
- id: 10
  file: 10.pdf
  title: Findings of the CONSTRAINT 2022 Shared Task on Detecting the Hero, the Villain, and the Victim in Memes
  authors: 
    - first_name: Shivam
      last_name: Sharma
      email:   shivams@iiitd.ac.in 
      institution: Indraprastha Institute of information Technology Delhi
    - first_name: Tharun   
      last_name: Suresh
      email:    tharun20119@iiitd.ac.in
      institution:  Indraprastha Institute of information Technology Delhi
    - first_name: Atharva 
      last_name: Kulkarni
      email:    atharvak@iiitd.ac.in
      institution: Indraprastha Institute of information Technology Delhi
    - first_name: Himanshi
      last_name:   Mathur
      email:    himanshi18037@iiitd.ac.in
      institution: Indraprastha Institute of information Technology Delhi
    - first_name: Preslav 
      last_name: Nakov 
      email:  pnakov@hbku.edu.qa 
      institution: Qatar Computing Research Institute, HBKU, Doha, Qatar
    - first_name: Md. Shad  
      last_name: Akhtar  
      email:  shad.akhtar@iiitd.ac.in
      institution: Indraprastha Institute of information Technology Delhi
    - first_name: Tanmoy  
      last_name: Chakraborty 
      email:  tanmoy@iiitd.ac.in
      institution: Indraprastha Institute of information Technology Delhi
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: memes | multimodal | role label | harmful memes | shared task
  abstract: "We present the findings of the shared task at the CONSTRAINT 2022 Workshop: Hero, Villain, and Victim: Dissecting harmful memes for Semantic role labeling of entities. The task aims to delve deeper into the domain of meme comprehension by deciphering the connotations behind the entities present in a meme. In more nuanced terms, the shared task focuses on determining the victimizing, glorifying, and vilifying intentions embedded in meme entities to explicate their connotations. To this end, we curate HVVMemes, a novel meme dataset of about 7000 memes spanning the domains of COVID-19 and US Politics, each containing entities and their associated roles: hero, villain, victim, or none. The shared task attracted 105 participants, but eventually only 6 submissions were made. Most of the successful submissions relied on fine-tuning pre-trained language and multimodal models along with ensembles. The best submission achieved an F1-score of 58.67."




- id: 4
  file: 4.pdf
  title: "DD-TIG at Constraint@ACL2022: Multimodal Understanding and Reasoning for Role Labeling of Entities in Hateful Memes"
  authors: 
    - first_name: Ziming
      last_name: Zhou
      email:  zhouziming@stu.pku.edu.cn
      institution: Peking University
    
    - first_name: Han
      last_name: Zhao
      email:  zhaohan@didiglobal.com
      institution: DD-TIG
    
    - first_name: Jingjing
      last_name: Dong
      email: djj@stu.pku.edu.cn
      institution: Peking University
    
    - first_name: Jun
      last_name: Gao
      email:  gaojun_i@didiglobal.com
      institution: DD-TIG
    
    - first_name: Xiaolong
      last_name: Liu
      email:  xlongliu@didiglobal.com
      institution: DD-TIG
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: multimodal | hateful meme | hostile content detection
  abstract: "The memes serve as an important tool in online communication, whereas some hateful memes endanger cyberspace by attacking certain people or subjects. Recent studies address hateful memes detection while further understanding of relationships of entities in memes remains unexplored. This paper presents our work at the Constraint@ACL2022 Shared Task: Hero, Villain and Victim: Dissecting harmful memes for semantic role labelling of entities. In particular, we propose our approach utilizing transformer-based multimodal models through a VCR method with data augmentation, continual pretraining, loss re-weighting, and ensemble learning. We describe the models used, the ways of preprocessing and experiments implementation. As a result, our best model achieves the Macro F1-score of 54.707 on the test set of this shared task."




- id: 5
  file: 5.pdf
  title: Are you a hero or a villain? A semantic role labelling approach for detecting harmful memes.
  authors: 
    - first_name: Shaik
      last_name: Fharook
      email: fharookshaik.5@gmail.com
      institution: Indian Institute of Information Technology, Dharwad
    - first_name: Syed
      last_name: Sufyan Ahmed
      email: sufyanahmed756@gmail.com
      institution: Indian Institute of Information Technology, Dharwad
    - first_name: Gurram
      last_name: Rithika
      email: rithika.gurram00@gmail.com
      institution: Indian Institute of Information Technology, Dharwad
    - first_name: Sumith Sai
      last_name: Budde
      email: sumithsaibudde@gmail.com
      institution: Indian Institute of Information Technology, Dharwad
    - first_name: Sunil
      last_name: Saumya 
      email: sunil.saumya@iiitdwd.ac.in
      institution: Indian Institute of Information Technology, Dharwad
    - first_name: Shankar
      last_name: Biradar
      email: shankar@iiitdwd.ac.in
      institution: Indian Institute of Information Technology, Dharwad
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Memes | Named Entity Recognition | Sentiment Analysis | Role labeling
  abstract: Identifying good and evil through representations of victimhood, heroism, and villainy (i.e., role labeling of entities) has recently caught the research community's interest. Because of the growing popularity of memes, the amount of offensive information published on the internet is expanding at an alarming rate. It generated a larger need to address this issue and analyze the memes for content moderation. Framing is used to show the entities engaged as heroes, villains, victims, or others so that readers may better anticipate and understand their attitudes and behaviors as characters. Positive phrases are used to characterize heroes, whereas negative terms depict victims and villains, and terms that tend to be neutral are mapped to others. In this paper, we propose two approaches to role label the entities of the meme as hero, villain, victim, or other through Named-Entity Recognition(NER), Sentiment Analysis, etc. With an F1-score of 23.855, our team secured eighth position in the Shared Task @ Constraint 2022.



- id: 6
  file: 6.pdf
  title: "Logically at the Constraint 2022: Multimodal role labelling"
  authors: 
    - first_name: Ludovic
      last_name: Kun
      email: kun.ludovic@gmail.com
      institution: Logically
    - first_name: Jayesh
      last_name: Bankoti
      email: jayeshbankoti@gmail.com
      institution: Logically
    - first_name: David
      last_name: Kiskovski
      email: david.k@logically.co.uk
      institution: Logically
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: unimodal | multimodal | ensembling | multi-class classification
  abstract: This paper describes our system for the Constraint 2022 challenge at ACL 2022, whose goal is to detect which entities are glorified, vilified or victimised, within a meme . The task should be done considering the perspective of the meme's author. In our work, the challenge is treated
    as a multi-class classification task. For a given pair of a meme and an entity, we need to classify whether the entity is being referenced as Hero, a Villain, a Victim or Other.
    Our solution combines (ensembling) different models based on Unimodal (Text only) model and Multimodal model (Text + Images). We conduct several experiments and benchmarks different competitive pre-trained transformers and vision models in this work. Our solution, based on an ensembling method, is ranked first on the leaderboard and obtains a macro F1-score of 0.58 on test set. The code for the experiments and results are available at https://bitbucket.org/logicallydevs/constraint_2022/src/master/




- id: 7
  file: 7.pdf
  title: Combining Language Models and Linguistic Information to Label Entities in Memes
  authors: 
    - first_name: Pranaydeep
      last_name: Singh
      email: pranaydeeps@gmail.com
      institution: Language and Translation Technology Team
    - first_name: Aaron
      last_name: Maladry
      email: aaron.maladry@ugent.be
      institution: Language and Translation Technology Team
    - first_name: Els
      last_name: Lefever
      email: els.lefever@ugent.be
      institution: Language and Translation Technology Team
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Transformers | Sentiment Analysis | Ensemble
  abstract: "This paper describes the system we developed for the shared task 'Hero, Villain and Victim: Dissecting harmful memes for Semantic role labelling of entities' organised in the framework of the Second Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situation (Constraint 2022).
    We present an ensemble approach combining transformer-based models and linguistic information, such as the presence of irony and implicit sentiment associated to the target named entities. The ensemble system obtains promising classification scores, resulting in a third place finish in the competition."



- id: 8
  file: 8.pdf
  title: "Detecting the Role of an Entity in Harmful Memes: Techniques and their Limitations"
  authors: 
    - first_name: Rabindra Nath
      last_name: Nandi
      email: rabindro.rath@gmail.com
      institution: BJIT Limited, Dhaka, Bangladesh
    - first_name: Firoj
      last_name: Alam
      email: firojalam@gmail.com
      institution: Qatar Computing Research Institute, HBKU, Doha, Qatar
    - first_name: Preslav
      last_name: Nakov
      email: pnakov@hbku.edu.qa
      institution: Qatar Computing Research Institute, HBKU, Doha, Qatar
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: harmful memes | semantic role labeling | unimodal | multimodal | attention | augmentation
  abstract: Harmful or abusive online content has been increasing over time and it has been raising concerns among social media platforms, government agencies, and policymakers. Such harmful or abusive content has a significant negative impact on society such as cyberbullying led to suicides, COVID-19 related rumors led to hundreds of deaths. The content that is posted and shared online can be textual, visual, a combination of both, or a meme. In this paper, we provide our study on detecting the roles of entities in harmful memes, which is part of the CONSTRAINT-2022 shared task. We report the results on the participated system. We further provide a comparative analysis on different experimental settings (i.e., unimodal, multimodal, attention, and augmentation).




- id: 9
  file: 9.pdf
  title: Fine-tuning and Sampling Strategies for Multimodal Role Labeling of Entities under Class Imbalance
  authors: 
    - first_name: Syrielle
      last_name: Montariol
      email: syrielle.montariol@inria.fr
      institution: INRIA Paris
    - first_name: Étienne
      last_name: Simon
      email: esimon@esimon.eu
      institution: Sorbonne Université, CNRS, ISIR
    - first_name: Arij
      last_name: Riabi
      email: arij.riabi@inria.fr
      institution: INRIA Paris
    - first_name: Djamé
      last_name: Seddah
      email: djame.seddah@free.fr
      institution: Alpage/Université Paris la Sorbonne
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Semantic Role Labeling | Multimodal model | Multimodal entity | Sub-sampling | Class imbalance
  abstract: We propose our solution to the multimodal semantic role labeling task from the CONSTRAINT'22 workshop. The task aims at classifying entities in memes into classes such as ``hero'' and ``villain''. We use several pre-trained multi-modal models to jointly encode the text and image of the memes, and implement three systems to classify the role of the entities. We propose dynamic sampling strategies to tackle the issue of class imbalance. Finally, we perform qualitative analysis on the representations of the entities.


- id: 11
  file: 11.pdf
  title: Document Retrieval and Claim Verification to Mitigate COVID-19 Misinformation
  authors: 
    - first_name: Megha
      last_name: Sundriyal
      email: meghas@iiitd.ac.in
      institution: Indraprastha Institute of Information Technology Delhi
    - first_name: Ganeshan   
      last_name: Malhotra  
      email: f20170512g@alumni.bits-pilani.ac.in 
      institution: BITS Pilani, Goa
    - first_name: Md Shad 
      last_name: Akhtar
      email:   shad.akhtar@iiitd.ac.in
      institution: Indraprastha Institute of Information Technology Delhi
    - first_name: Shubhashis
      last_name:   Sengupta  
      email: shubhashis.sengupta@accenture.com
      institution: Indraprastha Institute of Information Technology Delhi
    - first_name: Andrew  
      last_name: Fano  
      email: andrew.e.fano@accenture.com
      institution: Indraprastha Institute of Information Technology Delhi
    - first_name: Tanmoy  
      last_name: Chakraborty 
      email: tanmoy@iiitd.ac.in
      institution: Indraprastha Institute of Information Technology Delhi
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Claim Verification | Misinformation | Document Retrieval | Twitter | BM25 model
  abstract: During the COVID-19 pandemic, the spread of misinformation on online social media has grown exponentially. Unverified bogus claims on these platforms regularly mislead people, leading them to believe in half-baked truths. The current vogue is to employ manual fact-checkers to verify claims to combat this avalanche of misinformation. However, establishing such claims' veracity is becoming increasingly challenging, partly due to the plethora of information available, which is difficult to process manually. Thus, it becomes imperative to verify claims automatically without human interventions. To cope up with this issue, we propose an automated claim verification solution encompassing two steps -- document retrieval and veracity prediction. For the retrieval module, we employ a hybrid search-based system with BM25 as a base retriever and experiment with recent state-of-the-art transformer-based models for re-ranking. Furthermore, we use a BART-based textual entailment architecture to authenticate the retrieved documents in the later step. We report experimental findings, demonstrating that our retrieval module outperforms the best baseline system by 10.32 NDCG@100 points. We escort a demonstration to assess the efficacy and impact of our suggested solution. As a byproduct of this study, we present an open-source, easily deployable, and user-friendly Python API that the community can adopt.




- id: 1
  file: 1.pdf
  title: "M-BAD: A Multilabel Dataset for Detecting Aggressive Texts and Their Targets"
  authors: 
    - first_name: Omar 
      last_name: Sharif
      email: omar.sharif@cuet.ac.bd
      institution: Department of Computer Science & Engineering, Chittagong University of Engineering & Technology (CUET)
    - first_name: Eftekhar
      last_name: Hossain
      email: eftekhar.hossain@cuet.ac.bd
      institution: Department of Computer Science & Engineering, Chittagong University of Engineering & Technology (CUET)
    - first_name:  Mohammed Moshiul
      last_name: Hoque
      email: omar.sharif@cuet.ac.bd
      institution: Department of Computer Science & Engineering, Chittagong University of Engineering & Technology (CUET) 
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Natural language processing | Text classification | Deep learning | Multilabel text dataset | Resource-constrained languages
  abstract: 
      "Recently, detection and categorization of undesired (e. g., aggressive, abusive, offensive, hate) content from online platforms has grabbed the attention of researchers because of its detrimental impact on society. Several attempts have been made to mitigate the usage and propagation of such content. However, most past studies were conducted primarily for English, where low-resource languages like Bengali remained out of the focus. Therefore, to facilitate research in this arena, this paper introduces a novel multilabel Bengali dataset (named M-BAD) containing 15650 texts to detect aggressive texts and their targets. Each text of M-BAD went through rigorous two-level annotations. At the primary level, each text is labelled as either aggressive or non-aggressive. In the secondary level, the aggressive texts have been further annotated into five fine-grained target classes: religion, politics, verbal, gender and race. Baseline experiments are carried out with different machine learning (ML), deep learning (DL) and transformer models, where Bangla-BERT acquired the highest weighted $f_1$-score in both detection (0.92) and target identification (0.83) tasks. Error analysis of the models exhibits the difficulty to identify context-dependent aggression, and this work argues that further research is required to address these issues."

- id: 2
  file: 2.pdf
  title: How does fake news use a thumbnail? CLIP-based Multimodal Detection on the Unrepresentative News Image
  authors: 
    - first_name: Hyewon 
      last_name: Choi
      email: soohi0966@gmail.com
      institution: Soongsil University
    - first_name: Yejun 
      last_name: Yoon
      email: yeayen789@gmail.com  
      institution: Soongsil University
    - first_name: Seunghyun 
      last_name: Yoon
      email: soohi0966@gmail.com
      institution: Adobe Research
    - first_name: Kunwoo 
      last_name: Park
      email: soohi0966@gmail.com
      institution: Soongsil University

  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Fake news | multimodal representation | news thumbnail | CLIP
  abstract: This study investigates how fake news use the thumbnail image for a news article. We aim at capturing the degree of semantic incongruity between news text and image by using the pretrained CLIP representation. Motivated by the stylistic distinctiveness in fake news text, we examine whether fake news tends to use an irrelevant image to the news content. Results show that fake news tends to have a high degree of semantic incongruity than general news. We further attempt to detect such image-text incongruity by training classification models on a newly generated dataset. A manual evaluation suggests our method can find news articles of which the thumbnail image is semantically irrelevant to news text with an accuracy of 0.8. We also release a new dataset of image and news text pairs with the incongruity label, facilitating future studies on the direction.
      

- id: 3
  file: 3.pdf
  title: "Detecting False Claims in Low-Resource Regions: A Case Study of Caribbean Islands"
  authors: 
    - first_name: Jason
      last_name: Lucas
      email: jsl5710@psu.edu
      institution: Pennsylvania State University
    - first_name: Limeng
      last_name: Cui
      email: lzc334@psu.edu 
      institution: Pennsylvania State University
    - first_name: Thai
      last_name: Le
      email: tql3@psu.edu 
      institution: Pennsylvania State University
    - first_name: Dongwon
      last_name: Lee
      email: dongwon@psu.edu  
      institution: Pennsylvania State University
    
  attributes:
    paper_type: long
    presentation_type: poster
    submitted_area: Fake news detection | Caribbean | Low-resource language | high-resource language | Machine learning | Transfer learning | CoAID | COVID-19 | Public Health
  abstract: The COVID-19 pandemic has created threats to global health control. Misinformation circulated on social media and news outlets has undermined public trust towards Government and health agencies. This problem is further exacerbated in developing countries or low-resource regions, where the news is not equipped with abundant English fact-checking information. In this paper, we make the first attempt to detect COVID-19 misinformation (in English, Spanish, and Haitian French) populated in the Caribbean regions, using the fact-checked claims in the US (in English). We started by collecting a dataset of Caribbean real & fake claims. Then we trained several classification and language models on COVID-19 in the high-resource language regions and transferred the knowledge to the Caribbean claim dataset. The experimental results of this paper reveal the limitations of current fake claim detection in low-resource regions and encourage further research on multi-lingual detection.


