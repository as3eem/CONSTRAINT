% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{devlin2018bert,
  title={BERT: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{li2019visualbert,
  title={VisualBERT: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{chen2019uniter,
  title={UNITER: Learning universal image-text representations},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  year={2019}
}

@article{kiritchenko2021confronting,
  title={Confronting abusive language online: A survey from the ethical and human rights perspective},
  author={Kiritchenko, Svetlana and Nejadgholi, Isar and Fraser, Kathleen C},
  journal={Journal of Artificial Intelligence Research},
  volume={71},
  pages={431--478},
  year={2021}
}
@inproceedings{gu2018look,
  title={Look, imagine and match: Improving textual-visual cross-modal retrieval with generative models},
  author={Gu, Jiuxiang and Cai, Jianfei and Joty, Shafiq R and Niu, Li and Wang, Gang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7181--7189},
  year={2018}
}

@article{gao2021logically,
  title={Logically at the Factify 2022: Multimodal Fact Verification},
  author={Gao, Jie and Hoffmann, Hella-Franziska and Oikonomou, Stylianos and Kiskovski, David and Bandhakavi, Anil},
  journal={arXiv preprint arXiv:2112.09253},
  year={2021}
}

@article{alam2021survey,
  title={A survey on multimodal disinformation detection},
  author={Alam, Firoj and Cresci, Stefano and Chakraborty, Tanmoy and Silvestri, Fabrizio and Dimitrov, Dimiter and Martino, Giovanni Da San and Shaar, Shaden and Firooz, Hamed and Nakov, Preslav},
  journal={arXiv preprint arXiv:2103.12541},
  year={2021}
}

@article{wankhade2022survey,
  title={A survey on sentiment analysis methods, applications, and challenges},
  author={Wankhade, Mayur and Rao, Annavarapu Chandra Sekhara and Kulkarni, Chaitanya},
  journal={Artificial Intelligence Review},
  pages={1--50},
  year={2022},
  publisher={Springer}
}

@inproceedings{sharma2022report,
    title={Findings of the CONSTRAINT 2022 Shared Task on Detecting the Hero, the Villain, and the Victim in Memes},
    author={Shivam Sharma and Tharun Suresh and Atharva Kulkarni and Himanshi Mathur and Preslav Nakov and Md. Shad Akhtar and Tanmoy Chakraborty},
    booktitle={Proceedings of the Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situations - CONSTRAINT 2022, Collocated with ACL 2022},
    year = {2022}} 

@article{muller2021multimodal,
  title={Multimodal news analytics using measures of cross-modal entity and context consistency},
  author={M{\"u}ller-Budack, Eric and Theiner, Jonas and Diering, Sebastian and Idahl, Maximilian and Hakimov, Sherzod and Ewerth, Ralph},
  journal={International Journal of Multimedia Information Retrieval},
  volume={10},
  number={2},
  pages={111--125},
  year={2021},
  publisher={Springer}
}

@inproceedings{adarsh2020yolo,
  title={YOLO v3-Tiny: Object Detection and Recognition using one stage improved model},
  author={Adarsh, Pranav and Rathi, Pratibha and Kumar, Manoj},
  booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)},
  pages={687--694},
  year={2020},
  organization={IEEE}
}

@article{su2019vl,
  title={VL-BERT: Pre-training of generic visual-linguistic representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  journal={arXiv preprint arXiv:1908.08530},
  year={2019}
}

@article{tan2019lxmert,
  title={LXMERT: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{he2020deberta,
  title={DeBERTa: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{liu2019roberta,
  title={RoBERTa: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{tan2019efficientnet,
  title={EfficientNet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{kim2021vilt,
  title={ViLT: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}


@article{kiela2019supervised,
  title={Supervised Multimodal Bitransformers for Classifying Images and Text},
  author={Kiela, Douwe and Bhooshan, Suvrat and Firooz, Hamed and Testuggine, Davide},
  journal={arXiv preprint arXiv:1909.02950},
  year={2019}
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{zhang2016joint,
  title={Joint face detection and alignment using multitask cascaded convolutional networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={IEEE signal processing letters},
  volume={23},
  number={10},
  pages={1499--1503},
  year={2016},
  publisher={IEEE}
}

@article{ando2005framework,
  title={A framework for learning predictive structures from multiple tasks and unlabeled data.},
  author={Ando, Rie Kubota and Zhang, Tong and Bartlett, Peter},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={11},
  year={2005}
}

@article{silvaaspect,
  title={Aspect-based Sentiment Analysis using BERT with Disentangled Attention},
  author={Silva, Emanuel H and Marcacini, Ricardo M}
}


@inproceedings{li2019bidirectional,
  title={Bidirectional LSTM with hierarchical attention for text classification},
  author={Li, Jianping and Xu, Yimou and Shi, Huaye},
  booktitle={2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
  volume={1},
  pages={456--459},
  year={2019},
  organization={IEEE}
}


@inproceedings{le2020adversarial,
  title={Adversarial filters of dataset biases},
  author={Le Bras, Ronan and Swayamdipta, Swabha and Bhagavatula, Chandra and Zellers, Rowan and Peters, Matthew and Sabharwal, Ashish and Choi, Yejin},
  booktitle={International Conference on Machine Learning},
  pages={1078--1088},
  year={2020},
  organization={PMLR}
}


@article{lu2019vilbert,
  title={ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={arXiv preprint arXiv:1908.02265},
  year={2019}
}

@article{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2611--2624},
  year={2020}
}

@article{sharma2020semeval,
  title={SemEval-2020 Task 8: Memotion Analysis--The Visuo-Lingual Metaphor!},
  author={Sharma, Chhavi and Bhageria, Deepesh and Scott, William and Pykl, Srinivas and Das, Amitava and Chakraborty, Tanmoy and Pulabaigari, Viswanath and Gamback, Bjorn},
  journal={arXiv preprint arXiv:2008.03781},
  year={2020}
}


@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={91--99},
  year={2015}
}


@inproceedings{Li2020OscarOA,
  title={Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks},
  author={Xiujun Li and Xi Yin and Chunyuan Li and Xiaowei Hu and Pengchuan Zhang and Lei Zhang and Lijuan Wang and Houdong Hu and Li Dong and Furu Wei and Yejin Choi and Jianfeng Gao},
  booktitle={ECCV},
  year={2020}
}